{
  "model": {
    "model_name": "GPT-350M",
    "num_layers": 24,
    "parameters": {
      "total_parameters_bytes": 1637662720,
      "parameters_per_layer_bytes": [
        218103808,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        50409472,
        209731584
      ]
    }
  },
  "execution_time": {
    "total_time_ms": 40.887723803007496,
    "forward_backward_time_ms": 26.810411581552597,
    "batch_generator_time_ms": 0.5383491516113281,
    "layernorm_grads_all_reduce_time_ms": 6.71452496519167,
    "embedding_grads_all_reduce_time_ms": 0.02234240476865636,
    "optimizer_time_ms": 5.3934103846846915,
    "layer_compute_total_ms": [
      0.502443696259667,
      1.0382157238480574,
      0.9683312508031361,
      0.9309879740554184,
      0.9294557883340142,
      0.9260075646572593,
      0.9337964100375108,
      0.9294557883340142,
      0.9300942258046525,
      0.9307326250534722,
      0.925496621670765,
      0.9461702859592984,
      0.9346898485174654,
      0.9271570966504463,
      0.9265184830988688,
      0.928689612887977,
      0.9237081277771448,
      0.9185964837666291,
      0.9160397363206503,
      0.9275402463889418,
      0.9988246920427198,
      0.9330305461848514,
      0.9247301611466531,
      0.9299665413689174,
      0.9382628566904013,
      0.29445898760419414
    ]
  },
  "execution_memory": {
    "total_memory_mb": 3041.3872825426793,
    "layer_memory_total_mb": [
      20.18854827920418,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      141.30209303306995,
      113.44969030491123
    ]
  }
}